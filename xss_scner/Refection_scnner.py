'''
Created on Dec 28, 2020

@author: Nasir uddin
'''

from pprint import pprint
from utility import get_all_forms, get_form_details, submit_form
   


#https://dev.to/fprime/how-to-create-a-web-crawler-from-scratch-in-python-2p46

def scan_xss(url):
    """
    Given a `url`, it prints all XSS vulnerable forms and 
    returns True if any is vulnerable, False otherwise
    """
    # get all the forms from the URL
    forms =get_all_forms(url)
    # print(f"[+] Detected {len(forms)} forms on {url}.")
    js_script = "<Script>alert('hi')</scripT>"
    # returning value
    is_vulnerable = False
    # iterate over all forms
    for form in forms:
        form_details = get_form_details(form)
        content = submit_form(form_details, url, js_script).content.decode()
        print("content is ",content)
        if js_script in content:
            print(f"[+] XSS Detected on {url}")
            print(f"[*] Form details:")
            pprint(form_details)
            is_vulnerable = True
    # won't break because we want to print available vulnerable forms
    return is_vulnerable         
        
                

    
        

def main():
    
    
    scan_xss("http://localhost:8090/hack_webdemo/reflection.jsp")
   
    
if __name__ == '__main__':
    main()
